% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/cea_policy_tree.R
\name{cea_policy_tree}
\alias{cea_policy_tree}
\title{Train a policy tree after a CEA forest.}
\usage{
cea_policy_tree(
  forest,
  X,
  WTP = NULL,
  depth = 2,
  ci.level = 0.95,
  robust.se = FALSE
)
}
\arguments{
\item{forest}{A trained CEA forest.}

\item{X}{A covariate matrix containing variables that are to be used in the policy tree.}

\item{WTP}{Willingness to pay for a one unit increase in the outcome. If NULL, the WTP supplied to the CEA forest is used.}

\item{depth}{The desired depth for the decision tree.}

\item{ci.level}{Desired significance level (for confidence intervals).}

\item{robust.se}{Whether or not robust (sandwich) standard errors are desired. Defaults to FALSE.}
}
\value{
Returns a trained policy tree.
}
\description{
\code{cea_policy_tree} Trains an efficient policy decision tree given a CEA forest (a wrapper for policytree::policy_tree).
}
\examples{
\dontrun{
To be added...
}
}
\references{
Athey, S., & Wager, S. (2017). Efficient policy learning. arXiv preprint arXiv:1702.02896.
}
